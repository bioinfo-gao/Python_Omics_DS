{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64996767",
   "metadata": {},
   "source": [
    "Transformers 库建立在 Pytorch 框架之上（Tensorflow 的版本功能并不完善），\n",
    "虽然官方宣称使用 Transformers 库并不需要掌握 Pytorch 知识，但是实际上我们还是需要通过 Pytorch 的 \n",
    "DataLoader 类来加载数据、使用 Pytorch 的优化器对模型参数进行调整等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d59e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 张量 (Tensor) 是深度学习的基础，例如常见的 0 维张量称为标量 (scalar)、1 维张量称为向量 (vector)、2 维张量称为矩阵 (matrix)。Pytorch 本质上就是一个基于张量的数学计算工具包，它提供了多种方式来创建张量：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ec0817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.empty(2, 3) # empty tensor (uninitialized), shape (2,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7d4f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4458, 0.4619, 0.9140],\n",
       "        [0.9060, 0.0209, 0.2170]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2, 3) # random tensor, each value taken from [0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c73a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3138,  0.4502, -1.1314],\n",
       "        [-0.7296,  1.2862,  0.3257]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3) # random tensor, each value taken from standard normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d9386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2, 3, dtype=torch.long) # long integer zero tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501271d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2, 3, dtype=torch.double) # double float zero tensor\n",
    "# tensor([[0., 0., 0.],\n",
    "#         [0., 0., 0.]], dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39667b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(10)\n",
    "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ad13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 3.8000, 2.1000],\n",
       "        [8.6000, 4.0000, 2.4000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = [[1.0, 3.8, 2.1], [8.6, 4.0, 2.4]]\n",
    "torch.tensor(array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b9fc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 3.8000, 2.1000],\n",
       "        [8.6000, 4.0000, 2.4000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "array = np.array([[1.0, 3.8, 2.1], [8.6, 4.0, 2.4]])\n",
    "torch.from_numpy(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856479ec",
   "metadata": {},
   "source": [
    "     PyTorch with CUDA Support conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540a48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# this code asures that pytotch can access the GPU\n",
    "# shift the conda env pytorh_GPU_cuda to the front\n",
    "import torch\n",
    "#print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4e7230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 2.5.1+cu121\n",
      "CUDA available True\n",
      "CUDA version 12.1\n",
      "GPU NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch, platform\n",
    "print(\"PyTorch\", torch.__version__) # 2.80+CPU is CPU , 2.5.2cu is CUDA\n",
    "print(\"CUDA available\", torch.cuda.is_available())\n",
    "print(\"CUDA version\", torch.version.cuda)\n",
    "print(\"GPU\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881d1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch build: 2.5.1+cu121\n",
      "Python: 3.12.4 64bit\n",
      "CUDA runtime (nvcc): Cuda compilation tools, release 12.6, V12.6.85\n"
     ]
    }
   ],
   "source": [
    "import torch, platform, subprocess, sys\n",
    "print(\"PyTorch build:\", torch.__version__)          #PyTorch now sees the CUDA 12.1 wheel (+cu121)\n",
    "print(\"Python:\", sys.version.split()[0], platform.architecture()[0])\n",
    "try:\n",
    "    print(\"CUDA runtime (nvcc):\", subprocess.check_output([\"nvcc\",\"--version\"], text=True).split(\"\\n\")[3])\n",
    "except FileNotFoundError:\n",
    "    print(\"CUDA runtime (nvcc): not found  ← this is OK, wheels bundle their own\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "225bf99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1834, 0.3073, 0.6088],\n",
       "        [0.1564, 0.9793, 0.0010]], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上面这些方式创建的张量会存储在内存中并使用 CPU 进行计算，如果想要调用 GPU 计算，需要直接在 GPU 中创建张量或者将张量送入到 GPU 中：\n",
    "\n",
    "torch.rand(2, 3).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587ab23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Random tensor on GPU: tensor([0.2047], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "x = torch.rand(1).cuda()\n",
    "print(\"Random tensor on GPU:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e392c114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2266, 0.7317, 0.8444],\n",
       "        [0.3671, 0.2194, 0.2224]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.rand(2, 3, device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5090fdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6558, 0.5874, 0.1886],\n",
       "        [0.9655, 0.4984, 0.4969]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.rand(2, 3).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "249baecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进行 view 操作的张量必须是连续的 (contiguous)，可以调用 is_conuous 来判断张量是否连续；如果非连续，需要先通过 contiguous 函数将其变为连续的。也可以直接调用 Pytorch 新提供的 reshape 函数，它与 view 功能几乎一致，并且能够自动处理非连续张量。\n",
    "\n",
    "# 转置 transpose 交换张量中的两个维度，参数为相应的维度：\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3c1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x.transpose(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49c21fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]]) torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 交换维度 permute 与 transpose 函数每次只能交换两个维度不同，permute 可以直接设置新的维度排列方式：\n",
    "\n",
    "x = torch.tensor([[[1, 2, 3], [4, 5, 6]]])\n",
    "print(x, x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d83249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 4]],\n",
      "\n",
      "        [[2, 5]],\n",
      "\n",
      "        [[3, 6]]]) torch.Size([3, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = x.permute(2, 0, 1)\n",
    "print(x, x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b3a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 广播机制\n",
    "# 前面我们都是假设参与运算的两个张量形状相同。在有些情况下，即使两个张量形状不同，也可以通过广播机制 (broadcasting mechanism) 对其中一个或者同时对两个张量的元素进行复制，使得它们形状相同，然后再执行按元素计算。\n",
    "\n",
    "# 例如，我们生成两个形状不同的张量：\n",
    "\n",
    "x = torch.arange(1, 4).view(3, 1) # shape (3,1) \n",
    "y = torch.arange(4, 6).view(1, 2) # shape (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11c3c3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 6],\n",
      "        [6, 7],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    " print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4afa2eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12).view(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a8aced4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x[1, 3] # element at row 1, column 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74d4cafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x[1:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9db6690f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  6, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38cf555f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  3],\n",
       "        [ 6,  7],\n",
       "        [10, 11]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 2:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_GPU_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
