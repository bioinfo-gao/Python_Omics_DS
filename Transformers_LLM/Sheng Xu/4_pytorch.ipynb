{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64996767",
   "metadata": {},
   "source": [
    "Transformers 库建立在 Pytorch 框架之上（Tensorflow 的版本功能并不完善），\n",
    "虽然官方宣称使用 Transformers 库并不需要掌握 Pytorch 知识，但是实际上我们还是需要通过 Pytorch 的 \n",
    "DataLoader 类来加载数据、使用 Pytorch 的优化器对模型参数进行调整等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d59e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 张量 (Tensor) 是深度学习的基础，例如常见的 0 维张量称为标量 (scalar)、1 维张量称为向量 (vector)、2 维张量称为矩阵 (matrix)。Pytorch 本质上就是一个基于张量的数学计算工具包，它提供了多种方式来创建张量：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ec0817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.9185e-31,  1.3116e-42,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.empty(2, 3) # empty tensor (uninitialized), shape (2,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e7d4f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0597, 0.7948, 0.3898],\n",
       "        [0.4318, 0.8445, 0.8419]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2, 3) # random tensor, each value taken from [0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6c73a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2076,  0.9583, -0.4509],\n",
       "        [-0.6981, -0.3623, -0.6361]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3) # random tensor, each value taken from standard normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b43d9386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2, 3, dtype=torch.long) # long integer zero tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "501271d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2, 3, dtype=torch.double) # double float zero tensor\n",
    "# tensor([[0., 0., 0.],\n",
    "#         [0., 0., 0.]], dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39667b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10)\n",
    "torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f67ad13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 3.8000, 2.1000],\n",
       "        [8.6000, 4.0000, 2.4000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = [[1.0, 3.8, 2.1], [8.6, 4.0, 2.4]]\n",
    "torch.tensor(array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80b9fc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 3.8000, 2.1000],\n",
       "        [8.6000, 4.0000, 2.4000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "array = np.array([[1.0, 3.8, 2.1], [8.6, 4.0, 2.4]])\n",
    "torch.from_numpy(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856479ec",
   "metadata": {},
   "source": [
    "     PyTorch with CUDA Support \n",
    "     conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6540a48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n"
     ]
    }
   ],
   "source": [
    "# this code asures that pytotch can access the GPU\n",
    "# shift the conda env pytorh_GPU_cuda to the front\n",
    "import torch\n",
    "#print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc4e7230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 2.5.1\n",
      "CUDA available True\n",
      "CUDA version 11.8\n",
      "GPU NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch, platform\n",
    "print(\"PyTorch\", torch.__version__) # 2.80+CPU is CPU , 2.5.2cu is CUDA\n",
    "print(\"CUDA available\", torch.cuda.is_available())\n",
    "print(\"CUDA version\", torch.version.cuda)\n",
    "print(\"GPU\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e881d1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch build: 2.8.0+cu126\n",
      "Python: 3.11.13 64bit\n",
      "CUDA runtime (nvcc): Cuda compilation tools, release 12.6, V12.6.85\n"
     ]
    }
   ],
   "source": [
    "import torch, platform, subprocess, sys\n",
    "print(\"PyTorch build:\", torch.__version__)          #PyTorch now sees the CUDA 12.1 wheel (+cu121)\n",
    "print(\"Python:\", sys.version.split()[0], platform.architecture()[0])\n",
    "try:\n",
    "    print(\"CUDA runtime (nvcc):\", subprocess.check_output([\"nvcc\",\"--version\"], text=True).split(\"\\n\")[3])\n",
    "except FileNotFoundError:\n",
    "    print(\"CUDA runtime (nvcc): not found  ← this is OK, wheels bundle their own\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "225bf99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6033, 0.7959, 0.3852],\n",
       "        [0.0942, 0.1345, 0.6468]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上面这些方式创建的张量会存储在内存中并使用 CPU 进行计算，如果想要调用 GPU 计算，需要直接在 GPU 中创建张量或者将张量送入到 GPU 中：\n",
    "\n",
    "torch.rand(2, 3).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4587ab23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Random tensor on GPU: tensor([0.4079], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "x = torch.rand(1).cuda()\n",
    "print(\"Random tensor on GPU:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e392c114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4028, 0.8158, 0.5686],\n",
       "        [0.1025, 0.6553, 0.3080]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.rand(2, 3, device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5090fdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2328, 0.0817, 0.6757],\n",
       "        [0.0998, 0.0417, 0.6276]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.rand(2, 3).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "249baecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进行 view 操作的张量必须是连续的 (contiguous)，可以调用 is_conuous 来判断张量是否连续；如果非连续，需要先通过 contiguous 函数将其变为连续的。也可以直接调用 Pytorch 新提供的 reshape 函数，它与 view 功能几乎一致，并且能够自动处理非连续张量。\n",
    "\n",
    "# 转置 transpose 交换张量中的两个维度，参数为相应的维度：\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c3c1970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x.transpose(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49c21fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]]) torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 交换维度 permute 与 transpose 函数每次只能交换两个维度不同，permute 可以直接设置新的维度排列方式：\n",
    "\n",
    "x = torch.tensor([[[1, 2, 3], [4, 5, 6]]])\n",
    "print(x, x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00d83249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 4]],\n",
      "\n",
      "        [[2, 5]],\n",
      "\n",
      "        [[3, 6]]]) torch.Size([3, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = x.permute(2, 0, 1)\n",
    "print(x, x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "780b3a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 广播机制\n",
    "# 前面我们都是假设参与运算的两个张量形状相同。在有些情况下，即使两个张量形状不同，也可以通过广播机制 (broadcasting mechanism) 对其中一个或者同时对两个张量的元素进行复制，使得它们形状相同，然后再执行按元素计算。\n",
    "\n",
    "# 例如，我们生成两个形状不同的张量：\n",
    "\n",
    "x = torch.arange(1, 4).view(3, 1) # shape (3,1) \n",
    "y = torch.arange(4, 6).view(1, 2) # shape (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11c3c3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 6],\n",
      "        [6, 7],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    " print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4afa2eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12).view(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a8aced4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x[1, 3] # element at row 1, column 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74d4cafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x[1:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9db6690f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  6, 10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38cf555f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  3],\n",
       "        [ 6,  7],\n",
       "        [10, 11]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. 卸载现有 Pillow（无论用 pip 还是 conda 装的）\n",
    "# # run in in terminal is better by ZHEN . because jupyter sometimes has issue with conda yes not show in cell \n",
    "# conda uninstall pillow -y \n",
    "# pip uninstall pillow  # 确保彻底清除!\n",
    "\n",
    "# # 2. 用 conda 重新安装（自动解决 DLL 依赖）\n",
    "# conda install pillow -c conda-forge -y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176ada6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('64bit', 'WindowsPE')\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.architecture())  # 应输出 ('64bit', 'WindowsPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abf54ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3.0\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "print(Image.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7829b053",
   "metadata": {},
   "source": [
    "cannot import name 'datasets' from 'torchvision' (unknown location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90255efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "print(pkg_resources.get_distribution(\"torchvision\").version)\n",
    "# # 从 pytorch 官方频道安装（自动匹配 CUDA 版本）\n",
    "#conda install torchvision -c pytorch -c nvidia\n",
    "# conda update torchvision -c pytorch -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b5bdf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.1\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7773fe5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e187b1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:03<00:00, 8.27MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 267kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.42M/4.42M [00:01<00:00, 4.35MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.15k/5.15k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n",
      "torch.Size([28, 28])\n",
      "Label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "print(img.shape)\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a5f3569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "#conda activate torch_cuda\n",
    "!python -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f69e9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([3]), tensor([4]), tensor([5]), tensor([6])]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "class MyIterableDataset(IterableDataset):\n",
    "\n",
    "    def __init__(self, start, end):\n",
    "        super(MyIterableDataset).__init__()\n",
    "        assert end > start\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.end))\n",
    "\n",
    "ds = MyIterableDataset(start=3, end=7) # [3, 4, 5, 6]\n",
    "# Single-process loading\n",
    "print(list(DataLoader(ds, num_workers=0)))\n",
    "# # Directly doing multi-process loading\n",
    "# print(list(DataLoader(ds, num_workers=2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
