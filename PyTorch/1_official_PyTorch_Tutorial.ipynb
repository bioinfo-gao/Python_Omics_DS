{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e86fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 如果你不确定当前环境里还有什么其他冲突包，最保险的方法是新建一个环境。\n",
    "# # 创建一个名为 'torch_env' 的新环境，指定 Python 3.11（更稳定）\n",
    "# conda create -n torch_env python=3.11\n",
    "\n",
    "# # 激活新环境\n",
    "# conda activate torch_env\n",
    "\n",
    "# # 安装 PyTorch (替换为你的 CUDA 版本)\n",
    "# conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "# %pip 会自动定位到当前 Jupyter Kernel 的 Python 解释器，确保包被安装到正确的位置。而 !pip 调用的是系统 Shell 中的 pip，可能安装到完全不同的 Python 环境中，导致你“装了但还是找不到”的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d701be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 激活你的环境（如 pytorch_GPU_cuda）\n",
    "# !conda activate pytorch_GPU_cuda # ! call system shell to activate environment  \n",
    "# # 卸载\n",
    "# !conda uninstall torchvision\n",
    "# # 重新安装（与 PyTorch 版本匹配）\n",
    "# !conda install torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24907633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 检查是否有 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334726fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3.0\n"
     ]
    }
   ],
   "source": [
    "#重装后，在 Python 中运行： sometine restart   the kernel will helpful  \n",
    "from PIL import Image\n",
    "print(Image.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad57f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.1\n",
      "c:\\Users\\zhen-\\anaconda3\\envs\\torch_cuda\\Lib\\site-packages\\torchvision\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "print(torchvision.__version__)\n",
    "print(torchvision.__file__)  # 查看安装位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e2c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc849a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# PyTorch offers domain-specific libraries such as TorchText, TorchVision, and TorchAudio, all of which include datasets. For this tutorial, we will be using a TorchVision dataset.The torchvision.datasets module contains Dataset objects for many real-world vision data like CIFAR, COCO (full list here). In this tutorial, we use the FashionMNIST dataset. Every TorchVision Dataset includes two arguments: transform and target_transform to modify the samples and labels respectively.\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db39a715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d81471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Creating Models\n",
    "# To define a neural network in PyTorch, we create a class that inherits from nn.Module. We define the layers of the network in the __init__ function and specify how data will pass through the network in the forward function. To accelerate operations in the neural network, we move it to the accelerator such as CUDA, MPS, MTIA, or XPU. If the current accelerator is available, we will use it. Otherwise, we use the CPU.\n",
    "\n",
    "#device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8194b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b17d3c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d310bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We also check the model’s performance against the test dataset to ensure it is learning.\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b1aa532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.306524  [   64/60000]\n",
      "loss: 2.289540  [ 6464/60000]\n",
      "loss: 2.274071  [12864/60000]\n",
      "loss: 2.270713  [19264/60000]\n",
      "loss: 2.261742  [25664/60000]\n",
      "loss: 2.221151  [32064/60000]\n",
      "loss: 2.234284  [38464/60000]\n",
      "loss: 2.197087  [44864/60000]\n",
      "loss: 2.199460  [51264/60000]\n",
      "loss: 2.167277  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 2.160701 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.169291  [   64/60000]\n",
      "loss: 2.154606  [ 6464/60000]\n",
      "loss: 2.102417  [12864/60000]\n",
      "loss: 2.122481  [19264/60000]\n",
      "loss: 2.074846  [25664/60000]\n",
      "loss: 2.007193  [32064/60000]\n",
      "loss: 2.038663  [38464/60000]\n",
      "loss: 1.959086  [44864/60000]\n",
      "loss: 1.970608  [51264/60000]\n",
      "loss: 1.898413  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 1.895288 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.925846  [   64/60000]\n",
      "loss: 1.892266  [ 6464/60000]\n",
      "loss: 1.787420  [12864/60000]\n",
      "loss: 1.830475  [19264/60000]\n",
      "loss: 1.717199  [25664/60000]\n",
      "loss: 1.666831  [32064/60000]\n",
      "loss: 1.684135  [38464/60000]\n",
      "loss: 1.590086  [44864/60000]\n",
      "loss: 1.618125  [51264/60000]\n",
      "loss: 1.508219  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.7%, Avg loss: 1.529840 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.593633  [   64/60000]\n",
      "loss: 1.559654  [ 6464/60000]\n",
      "loss: 1.422479  [12864/60000]\n",
      "loss: 1.490553  [19264/60000]\n",
      "loss: 1.367875  [25664/60000]\n",
      "loss: 1.362718  [32064/60000]\n",
      "loss: 1.367231  [38464/60000]\n",
      "loss: 1.298903  [44864/60000]\n",
      "loss: 1.334300  [51264/60000]\n",
      "loss: 1.230546  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 1.262244 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.334676  [   64/60000]\n",
      "loss: 1.320403  [ 6464/60000]\n",
      "loss: 1.165790  [12864/60000]\n",
      "loss: 1.266581  [19264/60000]\n",
      "loss: 1.136848  [25664/60000]\n",
      "loss: 1.162327  [32064/60000]\n",
      "loss: 1.174223  [38464/60000]\n",
      "loss: 1.117307  [44864/60000]\n",
      "loss: 1.158305  [51264/60000]\n",
      "loss: 1.070219  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.096099 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece78cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
