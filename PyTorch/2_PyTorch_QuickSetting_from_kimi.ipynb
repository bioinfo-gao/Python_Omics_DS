{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34e95bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m==== Software Stack ====\u001b[0m\n",
      "Python     : 3.11.13\n",
      "PyTorch    : 2.6.0+cu124\n",
      "CUDA Build : 12.4\n",
      "cuDNN      : 90100\n",
      "\u001b[95m==== CPU ====\u001b[0m\n",
      "CPU        : AMD64 Family 25 Model 80 Stepping 0, AuthenticAMD\n",
      "Cores      : 6\n",
      "Threads    : 12\n",
      "\u001b[95m==== GPU ====\u001b[0m\n",
      "GPU Count  : 1\n",
      "  GPU 0  : NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "         Memory : 6143 MB\n",
      "         Compute: 8.6\n",
      "\u001b[96m---- Real-Time Utilization ----\u001b[0m\n",
      "  GPU 0: 0% | Memory 0/6144 MB\n",
      "\u001b[95m==== Distributed / Env ====\u001b[0m\n",
      "RANK                 : Not set\n",
      "LOCAL_RANK           : Not set\n",
      "WORLD_SIZE           : Not set\n",
      "MASTER_ADDR          : Not set\n",
      "MASTER_PORT          : Not set\n",
      "CUDA_VISIBLE_DEVICES : Not set\n",
      "\u001b[95m==== Reproducibility ====\u001b[0m\n",
      "Random seed set to 42 for CPU & all GPUs.\n",
      "\u001b[95m==== Default Device ====\u001b[0m\n",
      "Default tensor placed on : cuda:0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "PyTorch 机器信息一键速查\n",
    "> python torch_sysinfo.py\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import subprocess\n",
    "import torch\n",
    "import psutil   # pip install psutil\n",
    "\n",
    "# ---------- 颜色工具 ----------\n",
    "class Color:\n",
    "    HEADER = \"\\033[95m\"\n",
    "    OKBLUE = \"\\033[94m\"\n",
    "    OKCYAN = \"\\033[96m\"\n",
    "    OKGREEN = \"\\033[92m\"\n",
    "    WARNING = \"\\033[93m\"\n",
    "    FAIL = \"\\033[91m\"\n",
    "    ENDC = \"\\033[0m\"\n",
    "    BOLD = \"\\033[1m\"\n",
    "\n",
    "def cprint(text, color=Color.OKGREEN):\n",
    "    print(color + text + Color.ENDC)\n",
    "\n",
    "# ---------- 软件栈 ----------\n",
    "cprint(\"==== Software Stack ====\", Color.HEADER)\n",
    "print(f\"Python     : {platform.python_version()}\")\n",
    "print(f\"PyTorch    : {torch.__version__}\")\n",
    "print(f\"CUDA Build : {torch.version.cuda}\")\n",
    "print(f\"cuDNN      : {torch.backends.cudnn.version()}\")\n",
    "\n",
    "# ---------- CPU ----------\n",
    "cprint(\"==== CPU ====\", Color.HEADER)\n",
    "cpu = platform.processor() or \"Unknown\"\n",
    "cores = psutil.cpu_count(logical=False)\n",
    "threads = psutil.cpu_count(logical=True)\n",
    "print(f\"CPU        : {cpu}\")\n",
    "print(f\"Cores      : {cores}\")\n",
    "print(f\"Threads    : {threads}\")\n",
    "\n",
    "# ---------- GPU ----------\n",
    "cprint(\"==== GPU ====\", Color.HEADER)\n",
    "if not torch.cuda.is_available():\n",
    "    cprint(\"No GPU detected.\", Color.FAIL)\n",
    "else:\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print(f\"GPU Count  : {n_gpu}\")\n",
    "    for i in range(n_gpu):\n",
    "        prop = torch.cuda.get_device_properties(i)\n",
    "        print(f\"  GPU {i}  : {prop.name}\")\n",
    "        print(f\"         Memory : {prop.total_memory // 1024**2} MB\")\n",
    "        print(f\"         Compute: {prop.major}.{prop.minor}\")\n",
    "    # 实时利用率\n",
    "    cprint(\"---- Real-Time Utilization ----\", Color.OKCYAN)\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"nvidia-smi\", \"--query-gpu=index,name,memory.used,memory.total,utilization.gpu\",\n",
    "             \"--format=csv,noheader,nounits\"],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        for line in result.stdout.strip().split(\"\\n\"):\n",
    "            idx, name, used, total, util = line.split(\", \")\n",
    "            print(f\"  GPU {idx}: {util}% | Memory {used}/{total} MB\")\n",
    "    except FileNotFoundError:\n",
    "        cprint(\"nvidia-smi not found; skip real-time util.\", Color.WARNING)\n",
    "\n",
    "# ---------- 分布式环境 ----------\n",
    "cprint(\"==== Distributed / Env ====\", Color.HEADER)\n",
    "dist_env_keys = [\"RANK\", \"LOCAL_RANK\", \"WORLD_SIZE\",\n",
    "                 \"MASTER_ADDR\", \"MASTER_PORT\", \"CUDA_VISIBLE_DEVICES\"]\n",
    "for k in dist_env_keys:\n",
    "    print(f\"{k:20} : {os.environ.get(k, 'Not set')}\")\n",
    "\n",
    "# ---------- 随机种子 ----------\n",
    "cprint(\"==== Reproducibility ====\", Color.HEADER)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "print(\"Random seed set to 42 for CPU & all GPUs.\")\n",
    "\n",
    "# ---------- 设备选择 ----------\n",
    "cprint(\"==== Default Device ====\", Color.HEADER)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = torch.rand(1, 1).to(device)\n",
    "print(f\"Default tensor placed on : {x.device}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
