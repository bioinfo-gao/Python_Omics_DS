{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bdf5ff6",
   "metadata": {},
   "source": [
    "Scikit-learn is an open-source machine learning library that provides simple and efficient tools for data analysis and modeling. It is built on NumPy, SciPy, and Matplotlib, making it a powerful tool for tasks like classification, regression, clustering, and dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5730bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ddacb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.2\n"
     ]
    }
   ],
   "source": [
    "    import sklearn\n",
    "    print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d6229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall scikit-learn # stick with only conda  , both pip and conda would produce conflicts\n",
    "# !pip uninstall scikit-learn -y            # should be beter \n",
    "# this time very slow uninstall, hence keep it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d40898b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\zhen-\\anaconda3\\envs\\torch_cuda\\lib\\site-packages (from scikit-learn) (2.0.1)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/8.9 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.4/8.9 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.4/8.9 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.2/8.9 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.5/8.9 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.8/8.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.1/8.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 5.6 MB/s  0:00:01\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.2-cp311-cp311-win_amd64.whl (38.7 MB)\n",
      "   ---------------------------------------- 0.0/38.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.6/38.7 MB 8.4 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.6/38.7 MB 7.2 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 3.7/38.7 MB 6.4 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 5.2/38.7 MB 6.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 6.6/38.7 MB 6.3 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 8.1/38.7 MB 6.5 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 9.4/38.7 MB 6.7 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 11.3/38.7 MB 6.8 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 12.8/38.7 MB 6.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 14.4/38.7 MB 7.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 16.3/38.7 MB 7.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 18.1/38.7 MB 7.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.4/38.7 MB 7.2 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 21.5/38.7 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 23.3/38.7 MB 7.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 25.4/38.7 MB 7.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.3/38.7 MB 7.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.3/38.7 MB 7.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.4/38.7 MB 7.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.5/38.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.1/38.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.2/38.7 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.7 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.7/38.7 MB 8.0 MB/s  0:00:04\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ---------------------------------------- 4/4 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc42e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff167e3",
   "metadata": {},
   "source": [
    "Classification - Logistic Regression Algorithm Example\n",
    "Logistic Regression is a binary classification algorithm that estimates probabilities of a binary outcome. It's used for problems like spam detection, medical diagnosis, and credit scoring. It's chosen for its simplicity, interpretability, and effectiveness in linearly separable datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "756c4e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy                 as     np\n",
    "import matplotlib.pyplot     as     plt\n",
    "from sklearn                 import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.metrics         import accuracy_score, classification_report\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardizing features\n",
    "scaler  = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train) # scalar \n",
    "X_test  = scaler.transform(X_test)      # using the same scalar\n",
    "\n",
    "# Training the logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train) # Training the model\n",
    "\n",
    "# Making predictions on the testing set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ce9732",
   "metadata": {},
   "source": [
    "Classification - KNN Classifier Algorithm Example\n",
    "K-Nearest Neighbors (KNN) algorithm classifies data points based on the majority class of their nearest neighbors. It's useful for simple classification tasks, particularly when data is not linearly separable or when decision boundaries are complex. It's used in recommendation systems, handwriting recognition, and medical diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7573b1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets        import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206033be",
   "metadata": {},
   "source": [
    "Linear Regression Algorithm Example\n",
    "Linear Regression fits a linear model to observed data points, predicting continuous outcomes based on input features. It's used when exploring relationships between variables and making predictions. Applications include economics, finance, engineering, and social sciences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29848da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.5558915986952425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets        import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model    import LinearRegression\n",
    "from sklearn.metrics         import mean_squared_error\n",
    "\n",
    "# Load the California Housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc8bc3",
   "metadata": {},
   "source": [
    "Clustering - KMeans Algorithm Example\n",
    "KMeans algorithm partitions data into k clusters based on similarity. It's used for unsupervised clustering tasks like customer segmentation, image compression, and anomaly detection. Ideal when data's structure is unknown but grouping is desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929cf7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 1 1 1 2 1 1 1 1\n",
      " 1 1 2 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 1\n",
      " 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhen-\\anaconda3\\envs\\torch_cuda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster  import KMeans\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Initialize the KMeans clustering model\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "\n",
    "# Fit the model to the data\n",
    "kmeans.fit(iris.data)\n",
    "\n",
    "# Get the cluster labels\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "print(\"Cluster Labels:\", cluster_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d026a21a",
   "metadata": {},
   "source": [
    "Dimensionality Reduction - PCA Example\n",
    "PCA (Principal Component Analysis) reduces the dimensionality of data by finding the most important features. It's used for visualizing high-dimensional data, noise reduction, and speeding up machine learning algorithms. Commonly applied in image processing, genetics, and finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98775a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (1797, 64)\n",
      "Reduced data shape: (1797, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets      import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "\n",
    "# Initialize PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Apply PCA to the data\n",
    "reduced_data = pca.fit_transform(digits.data)\n",
    "\n",
    "print(\"Original data shape:\", digits.data.shape)\n",
    "print(\"Reduced data shape:\", reduced_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeebad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target names: ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Type of X is: <class 'numpy.ndarray'>\n",
      "\n",
      "dim of X is: 2\n",
      "\n",
      "shape of X is: (150, 4)\n",
      "\n",
      "First 5 rows of X:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris \n",
    "iris = load_iris() \n",
    "\n",
    "X = iris.data \n",
    "y = iris.target \n",
    "  \n",
    "feature_names = iris.feature_names \n",
    "target_names = iris.target_names \n",
    "  \n",
    "print(\"Feature names:\", feature_names) \n",
    "print(\"Target names:\", target_names) \n",
    "\n",
    "print(\"\\nType of X is:\", type(X)) \n",
    "print(\"\\ndim of X is:\", X.ndim) \n",
    "print(\"\\nshape of X is:\", X.shape)  # <<=============== dim in R\n",
    "\n",
    "print(\"\\nFirst 5 rows of X:\\n\", X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b00cb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape: (90, 4)\n",
      "X_test Shape: (60, 4)\n",
      "Y_train Shape: (90,)\n",
      "Y_test Shape: (60,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "print(\"X_train Shape:\",  X_train.shape)\n",
    "print(\"X_test Shape:\", X_test.shape)\n",
    "print(\"Y_train Shape:\", y_train.shape)\n",
    "print(\"Y_test Shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "873e1a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded feature: [1 2 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorical_feature = ['cat', 'dog', 'dog', 'cat', 'bird']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoded_feature = encoder.fit_transform(categorical_feature)\n",
    "\n",
    "print(\"Encoded feature:\", encoded_feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
